# We modified this file.
# The original one is available at https://github.com/lmnt-com/wavegrad
# 
# Shinozaki Lab Tokyo Tech
# http://www.ts.ip.titech.ac.jp/
# 2022
# ==============================================================================

# Copyright 2020 LMNT, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import numpy as np
import os
import torch
import torchaudio

from argparse import ArgumentParser

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from wavegrad.params import AttrDict
from wavegrad.model import WaveGrad


models = {}
def make_model(model_dir=None, params=None, device=torch.device('cuda')):
  # Lazy load model.
  if not model_dir in models:
    print(model_dir)
    if os.path.exists(f'{model_dir}/weights.pt'):
      checkpoint = torch.load(f'{model_dir}/weights.pt')
    else:
      checkpoint = torch.load(model_dir)

    if params is None: params = checkpoint['params']
    if 'num_action' not in params: params['num_action'] = 20 # for compatibility

    model = WaveGrad(AttrDict(), torch.nn.Embedding(params['num_action'], 50)).to(device)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    models[model_dir] = model


  model = models[model_dir]
  model.params.override(params)
  return model


def predict_using_model(action, model, device=torch.device('cuda'), noise_set = None):
  with torch.no_grad():
    beta = np.array(model.params.noise_schedule)
    alpha = 1 - beta
    alpha_cum = np.cumprod(alpha)
    action = action.to(device)

    if noise_set is None:
      noise_set = torch.randn(len(alpha), action.shape[0], model.params.wave_len, device=device) #non-deterministic if not specified

    audio = noise_set[0]
    noise_scale = torch.from_numpy(alpha_cum**0.5).float().unsqueeze(1).to(device)

    for n in range(len(alpha) - 1, -1, -1):
      c1 = 1 / alpha[n]**0.5
      c2 = (1 - alpha[n]) / (1 - alpha_cum[n])**0.5
      audio = c1 * (audio - c2 * model(audio, action, noise_scale[n]).squeeze(1))
      if n > 0:
        noise = noise_set[len(alpha)-n]
        sigma = ((1.0 - alpha_cum[n-1]) / (1.0 - alpha_cum[n]) * beta[n])**0.5
        audio += sigma * noise
      audio = torch.clamp(audio, -1.0, 1.0)
  return audio, model.params.sample_rate


def predict(action, param_path, params=None, device=torch.device('cuda'), noise_set=None):
  model = make_model(param_path, params, device)
  audio, sr = predict_using_model(action, model, device, noise_set)
  return audio, sr


def main(args):
  spectrogram = torch.from_numpy(np.load(args.spectrogram_path))
  params = {}
  if args.noise_schedule:
    params['noise_schedule'] = torch.from_numpy(np.load(args.noise_schedule))
  audio, sr = predict(spectrogram, model_dir=args.model_dir, params=params)
  torchaudio.save(args.output, audio.cpu(), sample_rate=sr)


if __name__ == '__main__':
  parser = ArgumentParser(description='runs inference on a spectrogram file generated by wavegrad.preprocess')
  parser.add_argument('model_dir',
      help='directory containing a trained model (or full path to weights.pt file)')
  parser.add_argument('spectrogram_path',
      help='path to a spectrogram file generated by wavegrad.preprocess')
  parser.add_argument('--noise-schedule', '-n', default=None,
      help='path to a custom noise schedule file generated by wavegrad.noise_schedule')
  parser.add_argument('--output', '-o', default='output.wav',
      help='output file name')
  main(parser.parse_args())
