{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92008bf-c02d-4c80-925f-ecfed4aea034",
   "metadata": {},
   "source": [
    "# ES-KMeans\n",
    "\n",
    "This program is an exercise for ES-KMeans\n",
    "> H. Kamper, K. Livescu, and S. J. Goldwater,\n",
    "\"An embedded segmental K-means model for unsupervised segmentation and clustering of speech,\"\n",
    "in *Proc. ASRU*, 2017.\n",
    "\n",
    "We have copied and modified some of the code available at\n",
    "https://github.com/kamperh/eskmeans,\n",
    "which is released under GNU General Public License version 3.\n",
    "\n",
    "Shinozaki Lab Tokyo Tech  \n",
    "http://www.ts.ip.titech.ac.jp/  \n",
    "2021\n",
    "\n",
    "## Table of contents\n",
    "1. Get landmarks\n",
    "1. Get segmentation list from landmarks\n",
    "1. MFCC extraction\n",
    "1. Embedding MFCC into a fixed length vector\n",
    "1. ES-KMeans\n",
    "1. Wave file segmentation\n",
    "1. Visualize segmentation\n",
    "\n",
    "## Install ES-KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612689a3-d08b-4583-b206-f1c5f415b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../tools\n",
    "!git clone https://github.com/kamperh/eskmeans.git\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddc995-16e2-410a-86a6-6a9a584a396b",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dbf98-214d-4f56-a9b1-b5cbad769670",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://tslab2.ip.titech.ac.jp/spolacq/data.zip\n",
    "!wget https://tslab2.ip.titech.ac.jp/spolacq/exp1.zip\n",
    "!wget https://tslab2.ip.titech.ac.jp/spolacq/fig.zip\n",
    "!unzip -q data.zip\n",
    "!unzip -q exp1.zip\n",
    "!unzip -q fig.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005abe08-d01d-466a-8b69-96ff55109fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import scipy.signal as signal\n",
    "\n",
    "sys.path.append(\"tools/eskmeans\")\n",
    "\n",
    "from tools.eskmeans.eskmeans.kmeans import KMeans\n",
    "from tools.eskmeans.eskmeans.eskmeans_wordseg import ESKmeans\n",
    "from utils.eskmeans_api import save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f2344-b767-493b-a655-b41c5f31efbb",
   "metadata": {},
   "source": [
    "## Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375d22d-ac49-4a66-ac21-7ed5dcdc6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Get landmarks\n",
    "        self.sylseg = \"exp1/seg/sylseg.csv\"\n",
    "        self.landmarks = \"exp1/seg/landmarks_syllable_seg.pkl\"\n",
    "        # Get segmentation list from landmarks\n",
    "        self.seglist = \"exp1/seg/seglist.pkl\"\n",
    "        # MFCC extraction\n",
    "        self.mfcc = \"exp1/seg/mfccs.pkl\"\n",
    "        # MFCC downsampling\n",
    "        self.embed = \"exp1/seg/embed_dur_dic.pkl\"\n",
    "        # ES-KMeans\n",
    "        self.txt_path = \"exp1/seg/eskseg_result.txt\"\n",
    "        self.pkl_path = \"exp1/seg/eskseg.pkl\"\n",
    "        # Wave file segmentation\n",
    "        self.wordseg = \"exp1/seg/eskseg.pkl\"\n",
    "        self.wavseg_dir = \"exp1/seg/segmented_wavs\"\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b622bd-68e3-4683-a7d7-b64f031eefd7",
   "metadata": {},
   "source": [
    "## Get landmarks\n",
    "\n",
    "Landmarks are the numbers of the frames, with a frame interval of 0.01 seconds, at which the syllables are segmented.\n",
    "We obtain the landmarks from the combined audio using MATLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110c1bc-d184-472a-a670-4c2688e66206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks():\n",
    "    with open(args.sylseg) as f:\n",
    "        lineList = f.readlines()\n",
    "\n",
    "    landmarks = []\n",
    "    for line in lineList:\n",
    "        bound_list = line.split()\n",
    "        landmarks_per_wav = [int(round(float(bound)*100.0)) for bound in bound_list]\n",
    "        landmarks_per_wav = landmarks_per_wav[1:]\n",
    "        landmarks.append(landmarks_per_wav)\n",
    "    \n",
    "    # with open(args.landmarks, \"wb\") as f:\n",
    "    #     pickle.dump(landmarks, f, -1)\n",
    "    # print(\"landmarks saved to: \" + args.landmarks)\n",
    "\n",
    "get_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48882f26-3cef-4ab1-9d93-8e0b10eeb36c",
   "metadata": {},
   "source": [
    "## Get segmentation list from landmarks\n",
    "\n",
    "The segmentation list is a list of candidates for word segmentation.\n",
    "Words are segmented by up to four syllables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953881ec-0d46-4b99-9830-78b3d2db921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LANDMARKS_MAX = 4\n",
    "\n",
    "def get_seglist_from_landmarks():\n",
    "    with open(args.landmarks, \"rb\") as f:\n",
    "        landmarks = pickle.load(f)\n",
    "    \n",
    "    seglist = []\n",
    "    for m in range(len(landmarks)):\n",
    "        seglist_per_wav = []\n",
    "        prev_landmark = 0\n",
    "        for i in range(len(landmarks[m])):\n",
    "            for j in landmarks[m][i:i + N_LANDMARKS_MAX]:\n",
    "                seglist_per_wav.append((prev_landmark, j))\n",
    "            prev_landmark = landmarks[m][i]\n",
    "        seglist.append(seglist_per_wav)\n",
    "\n",
    "    # with open(args.seglist, \"wb\") as f:\n",
    "    #     pickle.dump(seglist, f, -1)\n",
    "\n",
    "\n",
    "get_seglist_from_landmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798a35f-1c56-4922-bd28-08e10d9999cb",
   "metadata": {},
   "source": [
    "## MFCC extraction\n",
    "\n",
    "We extract the MFCC from the combined audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea80046-7a33-42db-ae3c-e4eb52f92710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc():\n",
    "    lines = [\"data/combined_sounds_8foods_interval_spolacq1.wav\"]\n",
    "    \n",
    "    mfccs = []\n",
    "    for line in lines:\n",
    "        wav_path = line.rstrip()\n",
    "        x, sr = librosa.load(wav_path, sr=44100)\n",
    "        mfccs_per_wav = librosa.feature.mfcc(x, sr=sr, hop_length=441, n_mfcc=20).T\n",
    "        print(\"for wav file \" + line.rstrip() + \", mfcc shape:\")\n",
    "        print(mfccs_per_wav.shape)\n",
    "        mfccs.append(mfccs_per_wav)\n",
    "\n",
    "    # with open(args.mfcc, \"wb\") as handle:\n",
    "    #     pickle.dump(mfccs, handle)\n",
    "\n",
    "\n",
    "# Comment out because it takes time.\n",
    "# extract_mfcc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93827b0-49ca-497c-883b-b7656f5615f2",
   "metadata": {},
   "source": [
    "## Embedding MFCC into a fixed length vector\n",
    "\n",
    "To perform K-Means clustering over segmentation list, we embed MFCC of each segment into a fixed-length vector.\n",
    "In this case, the length is $\\mathrm{n\\_mfcc}\\times10=20\\times10=200$.\n",
    "The `durations` of a segment is used as a weight in the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ecf7b-6e2f-43d5-a55f-028fa518c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_downsampling():\n",
    "    with open(args.mfcc, \"rb\") as handle:\n",
    "        mfccs = pickle.load(handle)\n",
    "    with open(args.seglist, \"rb\") as handle:\n",
    "        seglist = pickle.load(handle)\n",
    "\n",
    "    embed_dur_dic = {}\n",
    "\n",
    "    embeddings  = []\n",
    "    durations   = []\n",
    "\n",
    "    for m in range(len(mfccs)):\n",
    "        embeddings_per_wav  = []\n",
    "        durations_per_wav   = []\n",
    "        for i, j in seglist[m]:\n",
    "            y = mfccs[m][i:j+1, :].T\n",
    "            y_new = signal.resample(y, 10, axis=1).flatten(\"C\")\n",
    "            embeddings_per_wav.append(y_new)\n",
    "            durations_per_wav.append(j + 1 - i)\n",
    "        embeddings.append(embeddings_per_wav)\n",
    "        durations.append(durations_per_wav)\n",
    "\n",
    "    embed_dur_dic[\"embeddings\"] = embeddings\n",
    "    embed_dur_dic[\"durations\"]  = durations\n",
    "\n",
    "    # with open(args.embed, \"wb\") as f:\n",
    "    #     pickle.dump(embed_dur_dic, f, -1)\n",
    "\n",
    "\n",
    "# Comment out because it takes time.\n",
    "# mfcc_downsampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9226d4-89b5-4d52-8341-435b20fc55c7",
   "metadata": {},
   "source": [
    "## ES-KMeans\n",
    "\n",
    "We perform word segmentation using ES-KMeans, which alternates between segmentation and clustering for many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd100ebe-48ad-48b5-a644-db6b339f02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eskmeans():\n",
    "    \n",
    "    # n_slices == num of landmarks\n",
    "    with open(args.landmarks, \"rb\") as handle:\n",
    "        landmarks = pickle.load(handle)\n",
    "    n_slices = [len(landmarks_per_wav) for landmarks_per_wav in landmarks]\n",
    "    \n",
    "    n_slices_max = 4\n",
    "    # n_iter = 100\n",
    "    n_iter = 10\n",
    "    p_boundary_init = 1.0\n",
    "\n",
    "    # get embeddings\n",
    "    with open(args.embed, \"rb\") as handle:\n",
    "        embed_dur_dic = pickle.load(handle)\n",
    "    \n",
    "    embeddings = embed_dur_dic[\"embeddings\"]\n",
    "    durations_raw = embed_dur_dic[\"durations\"]\n",
    "\n",
    "    # number of wav files\n",
    "    num_wav_files = len(landmarks)\n",
    "\n",
    "    # get Vector IDs\n",
    "    vec_ids = []\n",
    "    durations = []\n",
    "    for m in range(num_wav_files):\n",
    "        vec_ids_per_wav = -1*np.ones((n_slices[m]**2 + n_slices[m])//2, dtype=int)\n",
    "        durations_per_wav = -1*np.ones((n_slices[m]**2 + n_slices[m])//2, dtype=int)\n",
    "        i_embed = 0\n",
    "        for cur_start in range(n_slices[m]):\n",
    "            for cur_end in range(cur_start, min(n_slices[m], cur_start + n_slices_max)):\n",
    "                cur_end += 1\n",
    "                t = cur_end\n",
    "                i = t*(t - 1)//2\n",
    "                vec_ids_per_wav[i + cur_start] = i_embed\n",
    "                durations_per_wav[i + cur_start] = durations_raw[m][i_embed]\n",
    "                i_embed += 1\n",
    "        vec_ids.append(vec_ids_per_wav)\n",
    "        durations.append(durations_per_wav)\n",
    "\n",
    "    # convert into dics\n",
    "    embedding_mats = {}\n",
    "    vec_ids_dict = {}\n",
    "    durations_dict = {}\n",
    "    landmarks_dict = {}\n",
    "    for m in range(num_wav_files):\n",
    "        embedding_mats[str(m)] = embeddings[m]\n",
    "        vec_ids_dict[str(m)] = vec_ids[m]\n",
    "        durations_dict[str(m)] = durations[m]\n",
    "        landmarks_dict[str(m)] = landmarks[m]\n",
    "\n",
    "\n",
    "    # Initialize model\n",
    "    K_max = 2\n",
    "    segmenter = ESKmeans(\n",
    "        K_max, embedding_mats, vec_ids_dict, durations_dict, landmarks_dict,\n",
    "        p_boundary_init=p_boundary_init, n_slices_max=n_slices_max\n",
    "        )\n",
    "\n",
    "    # Perform inference\n",
    "    record = segmenter.segment(n_iter=n_iter)\n",
    "\n",
    "    # save assignment results\n",
    "    # save(segmenter.acoustic_model, None, args.txt_path, args.pkl_path)\n",
    "\n",
    "\n",
    "eskmeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63625bf4-99ed-40f0-b7be-61e1475d2adc",
   "metadata": {},
   "source": [
    "## Wave file segmentation\n",
    "\n",
    "We segment the combined audio using the result of ES-KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecaad6b-aeec-47ba-9d0f-06183d1e6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "\n",
    "def wav_segmentation():\n",
    "\n",
    "    wavs = [AudioSegment.from_wav(\"data/combined_sounds_8foods_interval_spolacq1.wav\")]\n",
    "\n",
    "    with open(args.seglist, \"rb\") as handle:\n",
    "        seglist = pickle.load(handle)\n",
    "    with open(args.wordseg, \"rb\") as handle:\n",
    "        result_dict = pickle.load(handle)\n",
    "\n",
    "    seglist_a = []\n",
    "    for i,s in enumerate(seglist):\n",
    "        for ss in s:\n",
    "            seglist_a.append((i,ss[0],ss[1]))\n",
    "\n",
    "    for key in result_dict.keys():\n",
    "        for seg_index in result_dict[key]:\n",
    "            # start and end time in milliseconds\n",
    "            wavi = seglist_a[seg_index][0]\n",
    "            wav = wavs[wavi]\n",
    "            t_start = seglist_a[seg_index][1] * 10\n",
    "            t_end   = seglist_a[seg_index][2] * 10\n",
    "            \n",
    "            for i in range(t_start//10, t_end//10):\n",
    "                val.append((wavi, i))\n",
    "\n",
    "            wav_segment = wav[t_start:t_end]\n",
    "            # wav_segment.export(args.wavseg_dir + \"/\" + str(key) + \"_\" + str(seg_index) + \".wav\", format=\"wav\")\n",
    "\n",
    "    if len(set(val)) != len(val): #there are at least one duplication\n",
    "        print(\"Error: There is an overlap between segmented wavs. The segmentation is FAILED.\", file=sys.stderr)\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "wav_segmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f89fa7-0060-44ae-93e2-bf9406796cd1",
   "metadata": {},
   "source": [
    "## Visualize segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fc7ef-2e5a-4129-85df-b49c1b475b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"data/combined_sounds_8foods_interval_spolacq1.wav\"\n",
    "wav, sr = librosa.load(wav_path)\n",
    "\n",
    "truncate_second = 11\n",
    "truncated_wav = wav[:sr*truncate_second]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(np.arange(len(truncated_wav))/sr, truncated_wav)\n",
    "plt.xlim([0, truncate_second])\n",
    "plt.xlabel(\"time [s]\")\n",
    "\n",
    "sylseg = list() # segmentation seconds\n",
    "wordseg = list() # segmentation seconds\n",
    "\n",
    "# Load syllable segmentation result\n",
    "with open(args.sylseg) as f:\n",
    "    line = f.read()\n",
    "\n",
    "for landmark in line.strip().split():\n",
    "    sylseg.append(float(landmark))\n",
    "\n",
    "# Load word segmentation result\n",
    "with open(args.seglist, \"rb\") as handle:\n",
    "    seglist = pickle.load(handle)\n",
    "with open(args.wordseg, \"rb\") as handle:\n",
    "    result_dict = pickle.load(handle)\n",
    "\n",
    "seglist_a = []\n",
    "for i,s in enumerate(seglist):\n",
    "    for ss in s:\n",
    "        seglist_a.append((i,ss[0],ss[1]))\n",
    "\n",
    "for key in result_dict.keys():\n",
    "    for seg_index in result_dict[key]:\n",
    "        # start and end time in milliseconds\n",
    "        t_start = seglist_a[seg_index][1] * 10 / 1000\n",
    "        t_end   = seglist_a[seg_index][2] * 10 / 1000\n",
    "        wordseg.append(t_start)\n",
    "        wordseg.append(t_end)\n",
    "\n",
    "plt.vlines(sylseg, color=\"black\", ymin=0, ymax=1, label=\"Syllable segmentation\")\n",
    "plt.vlines(wordseg, color=\"red\", ymin=-1, ymax=0, label=\"Word segmentation\")\n",
    "plt.legend(fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
